{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "intro-header"
      },
      "source": [
        "<div align=\"left\" style=\"background-color: #008080; padding: 20px 10px;\">\n",
        "<h3><b>IDEAS - Institute of Data Engineering, Analytics and Science Foundation</b></h3>\n",
        "<p>Spring Internship Program 2026</p>\n",
        "<hr style=\"width:100%;\">\n",
        "<h3><b>Project Title:</b> Imagedata Augmentation and Image Classification</h3>\n",
        "<h4>Project Notebook</h4>\n",
        "\n",
        "<blockquote style=\"border-left: 4px solid #4285F4; padding-left: 15px;\">\n",
        "  <strong>Created by:</strong> Koustab Ghosh<sup>1</sup> & Sujoy Kumar Biswas<sup>2</sup><br>\n",
        "  <strong>Designation:</strong>\n",
        "  <ol style=\"margin-top: 5px; padding-left: 20px; font-size: 0.9em;\">\n",
        "    <li>Researcher, IDEAS-TIH, Indian Statistical Institute, Kolkata</li>\n",
        "    <li>Head of Research & Innovation, IDEAS-TIH, Indian Statistical Institute, Kolkata</li>\n",
        "  </ol>\n",
        "</blockquote>\n",
        "<hr style=\"width:100%;\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "points": 5,
        "id": "q1-markdown"
      },
      "source": [
        "### Question 1: Import Libraries and Load Image (5 Marks)\n",
        "\n",
        "Import `numpy` as `np` and `cv2`. Download the image 'moon-pexels-frank-cone.jpg' from https://drive.google.com/drive/folders/1TeLp4U4NsXCSgClbF7ODBsaLKpHSWeQr?usp=sharing and load it into a variable named `original_image` using OpenCV. Print the shape of the loaded image.\n",
        "\n",
        "**Hint:** Use `cv2.imread()` to load the image and `.shape` to get its dimensions.\n",
        "\n",
        "**Expected Output:** A tuple representing the shape of the image (height, width, channels)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "q1-code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6b169c6-c8ed-4ecf-9124-f0d32d6e0524"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(800, 640, 3)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "original_image = cv2.imread('moon-pexels-frank-cone.jpg')\n",
        "print(original_image.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "points": 5,
        "id": "q2-markdown"
      },
      "source": [
        "### Question 2: Convert to Grayscale (5 Marks)\n",
        "\n",
        "Convert the `original_image` to grayscale using OpenCV's `cvtColor` function. Store the result in a variable named `grayscale_image`. Print the shape of the new grayscale image.\n",
        "\n",
        "**Hint:** Use `cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)`. The shape of the grayscale image will have two dimensions instead of three.\n",
        "\n",
        "**Expected Output:** A tuple representing the shape of the grayscale image (height, width)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "q2-code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7c0c616-18ef-4781-9a99-97d1954ab09f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(800, 640)\n"
          ]
        }
      ],
      "source": [
        "# Converting it to grayscale\n",
        "grayscale_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Printig shape\n",
        "print(grayscale_image.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "points": 5,
        "id": "q3-markdown"
      },
      "source": [
        "### Question 3: Save the Grayscale Image (5 Marks)\n",
        "\n",
        "Save your `grayscale_image` to a file named `graymoon.jpg`.\n",
        "\n",
        "**Hint:** Use the `cv2.imwrite('filename.jpg', image_variable)` function.\n",
        "\n",
        "**Expected Output:** No direct output, but a file named `graymoon.jpg` will be created in your workspace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "q3-code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34b77b76-69bc-461f-9c1e-3723b51faadd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Saving grayscale image to show in file panel\n",
        "cv2.imwrite('graymoon.jpg', grayscale_image)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "points": 10,
        "id": "q4-markdown"
      },
      "source": [
        "### Question 4: Shift the Image (10 Marks)\n",
        "\n",
        "Create a transformation matrix `M` to shift the `original_image` 50 pixels to the right and 100 pixels down. Apply this transformation using `cv2.warpAffine` and store the result in `shifted_image`. Print the shape of `shifted_image`.\n",
        "\n",
        "**Hint:** The matrix `M` will be a 2x3 NumPy float32 array: `np.float32([[1, 0, 50], [0, 1, 100]])`. The output shape should be the same as the original image.\n",
        "\n",
        "**Expected Output:** The shape of the shifted image, which will be identical to the original image's shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "q4-code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dfa6481-9792-408d-e4a0-298d815495d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(800, 640, 3)\n"
          ]
        }
      ],
      "source": [
        "# Creating a transformation matrix\n",
        "M = np.float32([[1, 0, 50],\n",
        "                [0, 1, 100]])\n",
        "\n",
        "# Applying transformation using hint\n",
        "shifted_image = cv2.warpAffine(original_image, M,\n",
        "                               (original_image.shape[1], original_image.shape[0]))\n",
        "\n",
        "# Printing shape\n",
        "print(shifted_image.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "points": 10,
        "id": "q5-markdown"
      },
      "source": [
        "### Question 5: Resize the Image (10 Marks)\n",
        "\n",
        "Resize the `original_image` to be 150 pixels wide and 100 pixels tall. Store the result in a variable named `resized_image` and print its new shape.\n",
        "\n",
        "**Hint:** Use the `cv2.resize()` function. The desired size is passed as a tuple `(width, height)`.\n",
        "\n",
        "**Expected Output:** The tuple `(100, 150, 3)` representing the new shape (height, width, channels)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "q5-code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1598705c-9630-4c96-d195-dea8a913f44c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 150, 3)\n"
          ]
        }
      ],
      "source": [
        "# Resizing with pixel width=150 and height=100\n",
        "resized_image = cv2.resize(original_image, (150, 100))\n",
        "\n",
        "print(resized_image.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "points": 10,
        "id": "q6-markdown"
      },
      "source": [
        "### Question 6: Rotate the Image (10 Marks)\n",
        "\n",
        "Rotate the `original_image` by 90 degrees counter-clockwise around its center. Store the result in a variable named `rotated_image` and print its shape.\n",
        "\n",
        "**Hint:** First, get the image dimensions. Then, create a rotation matrix using `cv2.getRotationMatrix2D(center, angle, scale)`. Finally, apply it with `cv2.warpAffine`.\n",
        "\n",
        "**Expected Output:** The shape of the rotated image. Note that the height and width will be swapped compared to the original."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "q6-code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f35611e3-8e0c-4d49-cbf1-4aa21954b719"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(640, 800, 3)\n"
          ]
        }
      ],
      "source": [
        "# We get dimensions\n",
        "(h, w) = original_image.shape[:2]\n",
        "\n",
        "# Geting center f image\n",
        "center = (w // 2, h // 2)\n",
        "\n",
        "# Creating rotation matrix\n",
        "M = cv2.getRotationMatrix2D(center, 90, 1.0)\n",
        "\n",
        "# Applying rotation\n",
        "rotated_image = cv2.warpAffine(original_image, M, (h, w))\n",
        "\n",
        "print(rotated_image.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "points": 10,
        "id": "q7-markdown"
      },
      "source": [
        "### Question 7: Download and Unzip Cat/Dog Data (10 Marks)\n",
        "\n",
        "Download the Cat and Dog image dataset from the following link https://s3.amazonaws.com/content.udacity-data.com/nd089/Cat_Dog_data.zip and then unzip it. This will create a 'Cat_Dog_data' directory.\n",
        "\n",
        "**Hint:** Download and unzip to extract the files.\n",
        "\n",
        "**Expected Output:** No direct Python output, but the cell's log should show the download and extraction process completing successfully."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "q7-code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebdefcf6-fb51-4abf-aaf3-63b04f507a03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-02-15 11:48:00--  https://s3.amazonaws.com/content.udacity-data.com/nd089/Cat_Dog_data.zip\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 16.15.181.101, 52.217.100.94, 52.216.244.166, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|16.15.181.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 580495262 (554M) [application/zip]\n",
            "Saving to: ‘Cat_Dog_data.zip.1’\n",
            "\n",
            "Cat_Dog_data.zip.1  100%[===================>] 553.60M  55.5MB/s    in 10s     \n",
            "\n",
            "2026-02-15 11:48:11 (53.1 MB/s) - ‘Cat_Dog_data.zip.1’ saved [580495262/580495262]\n",
            "\n",
            "Archive:  Cat_Dog_data.zip\n",
            "replace Cat_Dog_data/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ],
      "source": [
        "!wget https://s3.amazonaws.com/content.udacity-data.com/nd089/Cat_Dog_data.zip\n",
        "!unzip Cat_Dog_data.zip\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "points": 15,
        "id": "q8-markdown"
      },
      "source": [
        "### Question 8: Create an Image Transform Pipeline (15 Marks)\n",
        "\n",
        "Import `torch` and necessary modules from `torchvision`. Define a transform pipeline named `train_transform` that resizes images to 255x255, randomly flips them horizontally, and then converts them to a tensor.\n",
        "\n",
        "**Hint:** Use `transforms.Compose()` with a list containing `transforms.Resize()`, `transforms.RandomHorizontalFlip()`, and `transforms.ToTensor()`.\n",
        "\n",
        "**Expected Output:** No output, but the `train_transform` object should be created successfully."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "q8-code"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((255, 255)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor()\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "points": 15,
        "id": "q9-markdown"
      },
      "source": [
        "### Question 9: Create an ImageFolder Dataset (15 Marks)\n",
        "\n",
        "Create an `ImageFolder` dataset named `train_dataset` from the `'Cat_Dog_data/train'` directory, applying the `train_transform` pipeline you just created. Print the total number of images found in the dataset.\n",
        "\n",
        "**Hint:** Use `datasets.ImageFolder(data_dir, transform=your_transform)`. The number of images is the length of the dataset object, which you can get with `len()`.\n",
        "\n",
        "**Expected Output:** A printout of the number of images in the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "q9-code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86ee507f-a786-446b-9e7f-5f5f3a2a6940"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22500\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets\n",
        "\n",
        "data_dir = 'Cat_Dog_data/train'\n",
        "\n",
        "train_dataset = datasets.ImageFolder(data_dir, transform=train_transform)\n",
        "\n",
        "print(len(train_dataset))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "points": 15,
        "id": "q10-markdown"
      },
      "source": [
        "### Question 10: Create a DataLoader (15 Marks)\n",
        "\n",
        "Create a `DataLoader` named `train_loader` from the `train_dataset`. Set the `batch_size` to 64 and `shuffle` to True. Then, retrieve one batch of images and labels from the loader and print the shape of the images tensor and the labels tensor.\n",
        "\n",
        "**Hint:** Use `torch.utils.data.DataLoader()`. To get one batch, use `images, labels = next(iter(train_loader))`. Print `images.shape` and `labels.shape`.\n",
        "\n",
        "**Expected Output:** Two printed tuples representing the shapes of the image batch and the label batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "q10-code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d8b1a5d-18d3-45f1-eed7-63f95503a3d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 255, 255])\n",
            "torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Gets one batch\n",
        "images, labels = next(iter(train_loader))\n",
        "\n",
        "print(images.shape)\n",
        "print(labels.shape)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}